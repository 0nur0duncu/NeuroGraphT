# ğŸ“š NeuroGraphT: EEG TabanlÄ± Uyku Evrelemesi Ä°Ã§in Ã‡izge Dikkat AÄŸlarÄ± ve Transformer Temelli Hibrit Derin Ã–ÄŸrenme YaklaÅŸÄ±mÄ±

**DetaylÄ± Teknik DokÃ¼mantasyon**

## ğŸ“‹ Ä°Ã§indekiler
1. [Proje Ã–zeti](#proje-Ã¶zeti)
2. [Veri Seti ve Ã–zellikleri](#veri-seti-ve-Ã¶zellikleri)
3. [Veri Seti: Sleep-EDF (DetaylÄ±)](#veri-seti-sleep-edf-detaylÄ±)
4. [Model Mimarisi: NeuroGraphT](#model-mimarisi-NeuroGraphT)
5. [Veri Ä°ÅŸleme Pipeline](#veri-iÌ‡ÅŸleme-pipeline)
6. [EÄŸitim ve DeÄŸerlendirme](#eÄŸitim-ve-deÄŸerlendirme)
7. [KarÅŸÄ±laÅŸtÄ±rmalÄ± Deneyler](#karÅŸÄ±laÅŸtÄ±rmalÄ±-deneyler)

---

## ğŸ¯ Proje Ã–zeti

### Proje AdÄ±
**NeuroGraphT**: EEG TabanlÄ± Uyku Evrelemesi Ä°Ã§in Ã‡izge Dikkat AÄŸlarÄ± ve Transformer Temelli Hibrit Derin Ã–ÄŸrenme YaklaÅŸÄ±mÄ±

### AmaÃ§
EEG (Electroencephalogram) sinyallerinden uyku evrelerini otomatik olarak sÄ±nÄ±flandÄ±rmak iÃ§in Graph Neural Network (GNN) ve Transformer tabanlÄ± zamansal kodlayÄ±cÄ± kullanan hibrit bir derin Ã¶ÄŸrenme mimarisi geliÅŸtirmek.

### YÃ¶ntem
**GNN ve Transformer TabanlÄ± Zamansal Kodlama:**

Ã–nerilen **NeuroGraphT** mimarisi Ã¼Ã§ ana bileÅŸenden oluÅŸur:

1. **Temporal Feature Extraction (CNN-Transformer Encoder)**
   - **1D CNN Layers**: Ham EEG sinyallerinden lokal temporal pattern'ler Ã§Ä±karÄ±r
   - **Transformer Encoder**: Self-attention mekanizmasÄ± ile uzun-menzilli temporal baÄŸÄ±mlÄ±lÄ±klarÄ± modeller
   - **Avantaj**: LSTM'e gÃ¶re paralelleÅŸtirilebilir, vanishing gradient problemi yok

2. **Adaptive Graph Construction (Graph Builder)**
   - Transformer Ã§Ä±ktÄ±larÄ±ndan **dinamik graf yapÄ±sÄ±** oluÅŸturur
   - **Node'lar**: Temporal feature'lardan tÃ¼retilen beyin bÃ¶lgeleri temsilcileri
   - **Edge'ler**: Pearson korelasyonu ile hesaplanan bÃ¶lge-bÃ¶lge etkileÅŸimleri
   - **Sparsity Control**: Value/Connection thresholding ile seyrek graf oluÅŸturma

3. **Graph Neural Network Encoder (GCN)**
   - Multi-layer GCN ile graf-yapÄ±sÄ± Ã¼zerinde Ã¶ÄŸrenme
   - **Node feature propagation**: KomÅŸu node'lardan bilgi toplayarak zenginleÅŸtirilmiÅŸ temsiller
   - **Global pooling**: TÃ¼m node'lardan graf-seviyesi embedding oluÅŸturma

4. **Self-Supervised Pre-training (Ã–zdenetimli Ã–n EÄŸitim)**
   - Contrastive learning ile EEG temsillerinin gÃ¼Ã§lendirilmesi
   - Temporal augmentation ve masking stratejileri
   - Transfer learning ile kÃ¼Ã§Ã¼k veri setlerinde performans artÄ±ÅŸÄ±

### Hedef Problem
**5 SÄ±nÄ±flÄ± Uyku Evresi SÄ±nÄ±flandÄ±rmasÄ±:**
- **W (Wake)**: UyanÄ±klÄ±k - Beta/Gamma aktivitesi dominanttÄ±r
- **N1**: Hafif uyku - Theta dalgalarÄ± baÅŸlar, geÃ§iÅŸ evresi
- **N2**: Orta derinlik uyku - K-kompleksleri ve uyku iÄŸcikleri (spindle)
- **N3**: Derin uyku (SWS) - Delta dalgalarÄ± dominanttÄ±r, slow-wave sleep
- **REM**: REM uykusu - HÄ±zlÄ± gÃ¶z hareketleri, rÃ¼ya evresi

---

## ğŸ“Š Veri Seti ve Ã–zellikleri

### Veri Seti
**Sleep-EDF Database Expanded** (PhysioNet 1.0.0)
- **Kaynak**: PhysioNet (https://physionet.org/content/sleep-edfx/1.0.0/)
- **Lisans**: Open Database License v1.0
- **EriÅŸim**: AÃ§Ä±k kaynak, Ã¼cretsiz

### Veri Seti Ä°statistikleri

| Ã–zellik | DeÄŸer |
|---------|-------|
| **Toplam KayÄ±t** | 197 whole-night polysomnographic (PSG) recordings |
| **Alt Gruplar** | Sleep Cassette (SC): 153 kayÄ±t, Sleep Telemetry (ST): 44 kayÄ±t |
| **Ã–zne SayÄ±sÄ±** | SC: 78 Ã¶zne (25-101 yaÅŸ), ST: 22 Ã¶zne |
| **KayÄ±t TÃ¼rÃ¼** | SC: Evde kayÄ±t, ST: Hastane ortamÄ± |
| **Toplam Veri Boyutu** | ~8.1 GB (uncompressed) |

### Sinyal Ã–zellikleri

**EEG KanallarÄ±:**
- **Fpz-Cz** (Frontal-Central): K-kompleks ve spindle detection iÃ§in optimal
- **Pz-Oz** (Parietal-Occipital): Delta wave detection iÃ§in optimal
- **Proje VarsayÄ±lanÄ±**: Fpz-Cz kanalÄ±

**Teknik Parametreler:**
```yaml
Sampling Rate: 100 Hz (EEG/EOG)
Epoch Duration: 30 saniye (AASM standardÄ±)
Samples per Epoch: 3000 (100 Hz Ã— 30s)
Bit Resolution: 16-bit
Dynamic Range: Â±200 ÂµV
Format: European Data Format (EDF/EDF+)
```

### SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (Tipik Sleep Cassette)

| SÄ±nÄ±f | Oran | AÃ§Ä±klama | Zorluk |
|-------|------|----------|--------|
| **W** | ~10-15% | UyanÄ±klÄ±k | Kolay (Beta/Gamma) |
| **N1** | ~5-10% | Hafif uyku | **Zor** (Az Ã¶rnek, belirsiz) |
| **N2** | ~45-50% | Orta uyku | Orta (Spindle/K-complex) |
| **N3** | ~15-20% | Derin uyku | Kolay (Delta dominanttÄ±r) |
| **REM** | ~20-25% | REM uykusu | Orta (Theta + gÃ¶z hareketi) |

**Dengesiz Veri Problemi:**
- N1 sÄ±nÄ±fÄ± **severely underrepresented** (~5-10%)
- N2 sÄ±nÄ±fÄ± **overrepresented** (~45-50%)
- **Ã‡Ã¶zÃ¼m**: Weighted Cross-Entropy Loss + Focal Loss + Data Augmentation

### Uyku Evresi AnotasyonlarÄ±

**Scoring StandardÄ±:** Rechtschaffen & Kales (1968) + AASM adaptasyonu
```python
Sleep Stage Mapping:
  - W (Wake)         â†’ Class 0
  - N1 (Stage 1)     â†’ Class 1
  - N2 (Stage 2)     â†’ Class 2
  - N3 (Stage 3+4)   â†’ Class 3  # AASM'de birleÅŸtirilmiÅŸ
  - REM (Stage R)    â†’ Class 4
  - Unknown/Movement â†’ -1 (atlanÄ±r)
```

### Veri Ã–n Ä°ÅŸleme Pipeline

1. **Otomatik Ä°ndirme**: AWS S3 Ã¼zerinden boto3 ile PhysioNet bucket'tan
2. **EDF Parsing**: MNE-Python ile ham sinyal yÃ¼kleme
3. **Hypnogram Alignment**: Annotation-signal senkronizasyonu
4. **Epoch Extraction**: 30s sliding window ile 3000-sample epoch'lar
5. **Normalization**: Subject-wise Z-score normalization
6. **Train/Val/Test Split**: Stratified split (70%/15%/15%) + subject-level ayrÄ±mÄ±

### Veri Augmentation Stratejileri

**Temporal Augmentation:**
- **Time Warping**: Temporal distortion (Â±5%)
- **Jittering**: Gaussian noise injection (SNR: 20-30 dB)
- **Scaling**: Amplitude scaling (0.8-1.2x)
- **Shifting**: Random temporal shift (Â±0.5s)

**Frequency Domain Augmentation:**
- **Band-pass Filtering**: Random filter shift
- **Frequency Masking**: Belirli frekans bantlarÄ±nÄ± maskeleme

**Self-Supervised Pre-training iÃ§in:**
- **Temporal Masking**: Rastgele epoch'larÄ± maskele
- **Contrastive Pairs**: Augmented versions as positive pairs
- **Hard Negative Mining**: Benzer ama farklÄ± sÄ±nÄ±ftan Ã¶rnekler

### Veri Kalite Kontrol

**Artifact Detection ve Filtreleme:**
- **Movement Artifacts**: "Movement time" etiketli epoch'lar atlanÄ±r
- **Unknown Stages**: "Sleep stage ?" etiketli epoch'lar atlanÄ±r
- **Signal Quality Check**: AmplitÃ¼d sÄ±nÄ±rÄ± kontrolÃ¼ (Â±200 ÂµV)
- **Continuity Check**: Eksik veya bozuk kanal kontrolÃ¼

**Final Dataset Statistics:**
```
Toplam PSG Recordings: 197
KullanÄ±lan Recordings: 153 (SC study)
Ortalama Epoch/Gece: ~800-1200 epoch
Toplam Epoch SayÄ±sÄ±: ~120,000-150,000 epoch (SC)
Train/Val/Test Split: ~105,000 / ~22,500 / ~22,500 epoch
```

### Veri Seti AvantajlarÄ±

âœ… **BÃ¼yÃ¼k Ã¶lÃ§ekli**: 197 whole-night recordings  
âœ… **Ã‡eÅŸitlilik**: GeniÅŸ yaÅŸ aralÄ±ÄŸÄ± (25-101)  
âœ… **Standardizasyon**: AASM/R&K scoring standardÄ±  
âœ… **AÃ§Ä±k eriÅŸim**: Tekrarlanabilir araÅŸtÄ±rma  
âœ… **Multi-channel**: EEG, EOG, EMG sinyalleri  
âœ… **Benchmark**: LiteratÃ¼rde yaygÄ±n kullanÄ±m  

### Veri Seti ZorluklarÄ±

âš ï¸ **Dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±**: N1 sÄ±nÄ±fÄ± underrepresented  
âš ï¸ **Inter-rater variability**: FarklÄ± uzmanlar arasÄ± tutarsÄ±zlÄ±k  
âš ï¸ **Tek kanal**: Klinik PSG'ye gÃ¶re sÄ±nÄ±rlÄ± elektrot  
âš ï¸ **Artifact'lar**: Evde kayÄ±t nedeniyle hareket artifact'larÄ±  
âš ï¸ **Subject variability**: Bireysel farklÄ±lÄ±klar (yaÅŸ, cinsiyet, saÄŸlÄ±k)

---

## ğŸ“Š Veri Seti: Sleep-EDF (DetaylÄ±)

### Genel Bilgiler

**Sleep-EDF Database** (PhysioNet)
- **Kaynak**: https://physionet.org/content/sleep-edfx/1.0.0/
- **Veri Tipi**: Polisomnografi (PSG) kayÄ±tlarÄ±
- **Toplam KayÄ±t**: 197 whole-night PSG recordings
- **Format**: European Data Format (EDF/EDF+)
- **EriÅŸim**: AÃ§Ä±k kaynak, Ã¼cretsiz

### Veri Seti YapÄ±sÄ±

#### Alt Gruplar
1. **Sleep Cassette (SC)**: 
   - Evde kayÄ±t edilen veriler
   - 153 SC* files / 78 Ã¶zne
   - 2 gece kayÄ±t (bazÄ± Ã¶zneler iÃ§in)
   - YaÅŸ aralÄ±ÄŸÄ±: 25-101 yaÅŸ, saÄŸlÄ±klÄ± Caucasian Ã¶zneler

2. **Sleep Telemetry (ST)**:
   - Hastanede kayÄ±t edilen veriler
   - 44 ST* files / 22 Ã¶zne
   - Temazepam etkisi Ã§alÄ±ÅŸmasÄ±
   - Daha kontrollÃ¼ ortam

**Proje varsayÄ±lanÄ±: SC (Sleep Cassette)**

### Sinyal Ã–zellikleri

#### EEG KanallarÄ±
Projede 2 ana kanal kullanÄ±labilir:
1. **EEG Fpz-Cz** (VarsayÄ±lan)
   - Frontal-Central bÃ¶lge
   - Uyku iÄŸcikleri ve K-komplekslerini iyi yakalar
   
2. **EEG Pz-Oz**
   - Parietal-Occipital bÃ¶lge
   - Delta dalgalarÄ±nÄ± daha iyi gÃ¶sterir

#### Teknik Parametreler
```yaml
# EEG/EOG Signals
Sampling Rate: 100 Hz
Epoch Duration: 30 saniye
Samples per Epoch: 3000 (100 Hz Ã— 30s)
Bit Resolution: 16-bit
Dynamic Range: Â±200 ÂµV (tipik EEG range)

# EMG Signal (SC files)
EMG Sampling: 1 Hz (envelope after rectification)
EMG Unit: ÂµV RMS (root-mean-square)

# Other Signals (SC files)
Respiration: 1 Hz
Body Temperature: 1 Hz
Event Marker: 1 Hz
```

### Veri Ã–n Ä°ÅŸleme

#### 1. **Otomatik Ä°ndirme** (`data/download.py`)
```python
from data.download import ensure_dataset

# Veri setini indir (yoksa) veya mevcut olanÄ± kullan
data_path = ensure_dataset(
    data_dir="dataset/sleep-edfx",  # Kaydedilecek dizin
    study='SC',                      # SC veya ST
    force_download=False,            # True ise yeniden indir
    verbose=True                     # Ä°lerleme gÃ¶ster
)
```

**AWS S3'ten Ä°ndirme:**
- Boto3 kullanarak PhysioNet S3 bucket'Ä±ndan indirilir
- Anonim eriÅŸim (credentials gerekmez)
- ~8.1 GB total uncompressed (197 PSG recordings)
- Sleep Cassette study: ~6 GB
- Sleep Telemetry study: ~2 GB

#### 2. **Sinyal YÃ¼kleme** (`data/preprocessing.py`)
```python
# EDF dosyasÄ±ndan EEG sinyalini yÃ¼kle
signal, sampling_rate = load_edf_file(
    psg_file="SC4001E0-PSG.edf",
    channel="EEG Fpz-Cz"
)
# signal: (n_samples,) numpy array
# sampling_rate: 100.0 Hz
```

**MNE-Python kullanÄ±mÄ±:**
- `mne.io.read_raw_edf()`: Ham EEG verilerini okur
- Otomatik kanal seÃ§imi ve veri tipi dÃ¶nÃ¼ÅŸÃ¼mÃ¼

#### 3. **Hypnogram Ä°ÅŸleme**
```python
# Uyku evresi anotasyonlarÄ±nÄ± yÃ¼kle
hypnogram = load_hypnogram("SC4001E0-Hypnogram.edf")
# [(onset, duration, stage_name), ...]
```

**Sleep Stage Annotations (Rechtschaffen & Kales 1968):**
```python
SLEEP_STAGE_DICT = {
    'Sleep stage W': 0,    # Wake (UyanÄ±klÄ±k)
    'Sleep stage 1': 1,    # N1 (NREM Stage 1)
    'Sleep stage 2': 2,    # N2 (NREM Stage 2)
    'Sleep stage 3': 3,    # N3 (NREM Stage 3 - Deep Sleep)
    'Sleep stage 4': 3,    # N3 (Stage 3 ve 4 modern AASM'de birleÅŸtirilir)
    'Sleep stage R': 4,    # REM (Rapid Eye Movement)
    'Sleep stage ?': -1,   # Unknown/Not scored (atlanÄ±r)
    'Movement time': -1,   # Movement artifact (atlanÄ±r)
}
# Not: Rechtschaffen & Kales manuel (1968) Stage 3 ve 4'Ã¼ ayÄ±rÄ±r,
# ancak modern AASM standardÄ± (2007) bunlarÄ± N3 olarak birleÅŸtirir
```

#### 4. **Epoch Ã‡Ä±karma**
```python
epochs, labels = extract_epochs(
    signal=signal,           # Ham sinyal
    hypnogram=hypnogram,     # Evre anotasyonlarÄ±
    sampling_rate=100,       # Hz
    epoch_sec=30            # Her epoch 30 saniye
)
# epochs: (n_epochs, 3000) - Her epoch 3000 Ã¶rnek
# labels: (n_epochs,) - 0-4 arasÄ± sÄ±nÄ±f etiketleri
```

#### 5. **Normalizasyon**
```python
def normalize_signal(signal):
    """Z-score normalizasyonu"""
    mean = np.mean(signal, axis=-1, keepdims=True)
    std = np.std(signal, axis=-1, keepdims=True)
    return (signal - mean) / std
```

**Neden Z-score?**
- FarklÄ± Ã¶zneler arasÄ± amplitÃ¼d farklÄ±lÄ±klarÄ±nÄ± giderir
- Mean=0, Std=1 daÄŸÄ±lÄ±mÄ± saÄŸlar
- Model eÄŸitimini hÄ±zlandÄ±rÄ±r ve stabilize eder

### Veri Seti Ä°statistikleri

#### Tipik SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (SC)
```
N2: ~45-50%  (En yaygÄ±n uyku evresi)
REM: ~20-25%
N3: ~15-20%
W: ~10-15%
N1: ~5-10%   (En az gÃ¶rÃ¼len evre)
```

#### Dengesiz Veri Problemi
**N1 sÄ±nÄ±fÄ± az temsil edilir** â†’ Bu nedenle:
- **Weighted Cross-Entropy Loss** kullanÄ±mÄ± Ã¶nerilir
- **F1-Score (Macro)** metriÄŸi accuracy'den daha anlamlÄ±dÄ±r
- **Stratified Split** ile train/val/test bÃ¶lme

### PyTorch Dataset SÄ±nÄ±fÄ±

```python
class SleepEDFDataset(Dataset):
    """Sleep-EDF iÃ§in PyTorch Dataset"""
    
    def __init__(self, signals, labels, transform=None):
        self.signals = torch.FloatTensor(signals)  # (N, 1, 3000)
        self.labels = torch.LongTensor(labels)      # (N,)
        self.transform = transform
    
    def __getitem__(self, idx):
        signal = self.signals[idx]  # (1, 3000)
        label = self.labels[idx]    # scalar
        
        if self.transform:
            signal = self.transform(signal)
        
        return signal, label
```

### Veri YÃ¼kleme Ã–rneÄŸi

```python
from data import load_sleep_edf_dataset, create_data_loaders

# Basit yÃ¼kleme
signals, labels, subject_indices = load_sleep_edf_dataset(
    data_dir="dataset/sleep-edfx",
    study='SC',
    channel='EEG Fpz-Cz',
    max_subjects=None,  # TÃ¼m Ã¶zneler
    normalize=True,
    verbose=True
)

# DataLoader oluÅŸturma
dataloaders = create_data_loaders(
    data_dir="dataset/sleep-edfx",
    batch_size=32,
    train_ratio=0.7,
    val_ratio=0.15,  # test_ratio = 0.15 (otomatik)
    random_seed=42,
    num_workers=0
)

train_loader = dataloaders['train']
val_loader = dataloaders['val']
test_loader = dataloaders['test']
```

---

## ğŸ—ï¸ Model Mimarisi: NeuroGraphT

### Genel BakÄ±ÅŸ

**NeuroGraphT** Ã¼Ã§ ana bileÅŸenden oluÅŸur:

```
Input EEG Signal (1, 3000)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CNN-Transformer Encoder     â”‚ â† Temporal feature extraction
â”‚   - CNN: Local patterns       â”‚
â”‚   - Transformer: Dependencies â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    H: (batch, seq_len, hidden)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Graph Builder            â”‚ â† Adaptive graph construction
â”‚   - Node creation             â”‚
â”‚   - Adjacency matrix          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Node Features + Adjacency
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       GCN Encoder             â”‚ â† Graph learning
â”‚   - Graph convolutions        â”‚
â”‚   - Node aggregation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Graph Embedding
        â†“
    Classifier (Linear)
        â†“
    Logits (5 classes)
```

---

### 1ï¸âƒ£ CNN-Transformer Encoder

#### CNN ModÃ¼lÃ¼ (`CNNTransformerEncoder`)

**AmaÃ§:** Ham EEG sinyalinden dÃ¼ÅŸÃ¼k-orta seviye Ã¶zellikler Ã§Ä±karmak

```python
# Input: (batch, 1, 3000)
self.cnn = nn.Sequential(
    # Layer 1: 1 â†’ 32 channels
    nn.Conv1d(1, 32, kernel_size=5, padding=2),
    nn.BatchNorm1d(32),
    nn.ReLU(),
    nn.MaxPool1d(2),      # Length: 3000 â†’ 1500
    nn.Dropout(0.1),
    
    # Layer 2: 32 â†’ 64 channels
    nn.Conv1d(32, 64, kernel_size=5, padding=2),
    nn.BatchNorm1d(64),
    nn.ReLU(),
    nn.MaxPool1d(2),      # Length: 1500 â†’ 750
    nn.Dropout(0.1),
    
    # Layer 3: 64 â†’ 128 channels
    nn.Conv1d(64, 128, kernel_size=5, padding=2),
    nn.BatchNorm1d(128),
    nn.ReLU(),
    nn.MaxPool1d(2),      # Length: 750 â†’ 375
    nn.Dropout(0.1),
)

# Adaptive pooling: 375 â†’ 64 (sabit uzunluk)
self.adaptive_pool = nn.AdaptiveAvgPool1d(64)
# Output: (batch, 128, 64)
```

**Ã–zellikler:**
- **Kernel Size 5**: EEG'de tipik 1-50 Hz frekans bantlarÄ±nÄ± yakalar
- **MaxPool**: Ã–zellik boyutunu azaltÄ±r, hesaplama verimliliÄŸi
- **BatchNorm**: EÄŸitimi stabilize eder
- **Dropout**: Overfitting'i Ã¶nler

#### Transformer ModÃ¼lÃ¼

**Neden LSTM yerine Transformer?**
- âœ… **Paralel hesaplama**: LSTM'den 3-5x hÄ±zlÄ±
- âœ… **Long-range dependencies**: Self-attention ile tÃ¼m pozisyonlar arasÄ±nda doÄŸrudan baÄŸlantÄ±
- âœ… **Positional encoding**: Temporal bilgi korunur
- âœ… **Better gradient flow**: Vanishing gradient problemi yok

```python
# CNN Ã§Ä±ktÄ±sÄ±nÄ± (batch, 128, 64) â†’ (batch, 64, 128) dÃ¶nÃ¼ÅŸtÃ¼r
x = x.permute(0, 2, 1)  # (batch, seq_len=64, channels=128)

# Transformer dim'e projeksiyon
x = self.input_projection(x)  # (batch, 64, 128) â†’ (batch, 64, 128)

# Positional encoding ekle
x = self.positional_encoding(x)

# Transformer encoding
encoder_layer = nn.TransformerEncoderLayer(
    d_model=128,          # Model boyutu
    nhead=8,              # Attention head sayÄ±sÄ±
    dim_feedforward=512,  # FFN hidden size
    dropout=0.1,
    activation='gelu',    # ReLU yerine GELU (daha smooth)
    batch_first=True      # (batch, seq, feature) formatÄ±
)
self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)

H = self.transformer(x)  # (batch, 64, 128)
```

**Positional Encoding:**
```python
PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```
- SinÃ¼zoidal fonksiyonlar ile pozisyon bilgisi
- Ã–ÄŸrenilmez (fixed), generalization iÃ§in Ã¶nemli

**Multi-Head Self-Attention:**
```
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V
```
- 8 head: FarklÄ± attention pattern'leri Ã¶ÄŸrenir
- d_k = 128/8 = 16 per head

---

### 2ï¸âƒ£ Graph Builder (Adaptif Graf OluÅŸturma)

**AmaÃ§:** Transformer Ã§Ä±ktÄ±sÄ±ndan beyin bÃ¶lgeleri arasÄ± etkileÅŸim grafÄ± oluÅŸturmak

```python
class GraphBuilder(nn.Module):
    def __init__(
        self,
        num_nodes: int = 16,        # N - DÃ¼ÄŸÃ¼m sayÄ±sÄ±
        sparsity: float = 25.0,     # a - Seyreklik (%)
        thresholding: str = "value" # EÅŸikleme yÃ¶ntemi
    )
```

#### AdÄ±mlar:

**1. Node Feature Ã‡Ä±karma**
```python
# H: (batch, seq_len=64, hidden=128)
H_flat = H.reshape(batch, -1)  # (batch, 64*128=8192)

# 16 node'a bÃ¶l
features_per_node = 8192 // 16 = 512
node_features = H_flat.reshape(batch, 16, 512)
# node_features: (batch, 16, 512)
```

**2. Korelasyon Matrisi Hesaplama**
```python
# Z-score normalization
node_norm = (node_features - mean) / std

# Pearson korelasyonu
correlation = torch.bmm(node_norm, node_norm.transpose(-2, -1))
correlation = correlation / feature_dim
# C: (batch, 16, 16) - Her (i,j) dÃ¼ÄŸÃ¼m Ã§ifti arasÄ± korelasyon
```

**3. Adjacency Matrix OluÅŸturma**

**YÃ¶ntem A: Value Thresholding**
```python
def _value_threshold(self, C):
    """
    En yÃ¼ksek %a korelasyon deÄŸerine sahip baÄŸlantÄ±larÄ± tut
    """
    percentile = 100 - sparsity  # 100-25 = 75
    threshold = np.percentile(C, percentile)
    adjacency = (C > threshold).float()
    
    # Self-loop'larÄ± kaldÄ±r
    adjacency = adjacency * (1 - eye)
    
    return adjacency
```

**YÃ¶ntem B: Connection Thresholding**
```python
def _connection_threshold(self, C):
    """
    Her dÃ¼ÄŸÃ¼m iÃ§in en gÃ¼Ã§lÃ¼ %a baÄŸlantÄ±yÄ± tut
    """
    n_connections = int(N * sparsity / 100)  # 16 * 0.25 = 4
    
    # Top-k en gÃ¼Ã§lÃ¼ baÄŸlantÄ±lar
    _, indices = torch.topk(C, k=n_connections, dim=-1)
    
    # Sparse adjacency matrix
    adjacency = torch.zeros_like(C)
    adjacency.scatter_(2, indices, C.gather(2, indices))
    
    # Simetrik yap (undirected graph)
    adjacency = torch.maximum(adjacency, adjacency.transpose(-2, -1))
    
    return adjacency
```

**Sparsity Parametresi (a):**
- **25%**: Daha seyrek graf â†’ Sadece gÃ¼Ã§lÃ¼ baÄŸlantÄ±lar
- **50%**: Daha yoÄŸun graf â†’ Daha fazla etkileÅŸim

**Thresholding KarÅŸÄ±laÅŸtÄ±rmasÄ±:**
| YÃ¶ntem | Avantaj | Dezavantaj |
|--------|---------|------------|
| **Value** | Global optimizasyon | Her node farklÄ± sayÄ±da baÄŸlantÄ± |
| **Connection** | Her node'a eÅŸit baÄŸlantÄ± | BazÄ± zayÄ±f baÄŸlantÄ±lar dahil olabilir |

---

### 3ï¸âƒ£ GCN Encoder (Graph Convolutional Network)

**AmaÃ§:** Graf yapÄ±sÄ±ndaki node feature'larÄ± Ã¶ÄŸrenerek global graph embedding elde etmek

```python
class GCNEncoder(nn.Module):
    def __init__(
        self,
        in_channels: int,      # 512 (node feature dim)
        hidden_channels: int = 128,
        num_layers: int = 3,
        dropout: float = 0.1
    )
```

#### Graph Convolution Ä°ÅŸlemi

```python
def forward(self, x, adj):
    """
    Args:
        x: (batch, N=16, F=512) - Node features
        adj: (batch, N=16, N=16) - Adjacency matrix
    Returns:
        graph_embedding: (batch, hidden_channels=128)
    """
    for layer in self.layers:
        # 1. KomÅŸu node'larÄ±n toplam feature'larÄ±nÄ± hesapla
        neighbor_sum = torch.bmm(adj, x)  # (batch, 16, 512)
        
        # 2. Kendi feature'Ä± ile birleÅŸtir
        combined = x + neighbor_sum        # (batch, 16, 512)
        
        # 3. Linear transformation
        x = layer(combined)                # (batch, 16, 128)
        x = F.relu(x)
        x = self.dropout(x)
    
    # 4. Global pooling (tÃ¼m node'larÄ± birleÅŸtir)
    graph_embedding = x.max(dim=1)[0]  # (batch, 128)
    
    return graph_embedding
```

**GCN FormÃ¼lÃ¼ (Simplified):**
```
h_i^(l+1) = Ïƒ(W^(l) Â· (h_i^(l) + Î£ h_j^(l)))
                              jâˆˆN(i)
```
- `h_i^(l)`: Node i'nin l. katmandaki feature'Ä±
- `N(i)`: Node i'nin komÅŸularÄ±
- `W^(l)`: Ã–ÄŸrenilen weight matrix
- `Ïƒ`: Activation function (ReLU)

**Katman SayÄ±sÄ± (num_layers=3):**
- **1 layer**: 1-hop neighbors (direkt komÅŸular)
- **2 layers**: 2-hop neighbors
- **3 layers**: 3-hop neighbors (daha global bilgi)

**Global Max Pooling:**
```python
# Her node'dan en Ã¶nemli feature'larÄ± al
graph_embedding = x.max(dim=1)[0]
```
- Alternatifler: Mean pooling, Sum pooling
- Max pooling: En diskriminatif feature'larÄ± yakalar

---

### 4ï¸âƒ£ Classifier (Son Katman)

```python
self.classifier = nn.Linear(gcn_hidden=128, num_classes=5)

logits = self.classifier(graph_embedding)  # (batch, 5)
```

**Output:**
- **Shape:** `(batch, 5)`
- **Logits:** Ham sÄ±nÄ±f skorlarÄ± (softmax Ã¶ncesi)
- **Classes:** [W, N1, N2, N3, REM]

---

### Tam Pipeline Ã–rneÄŸi

```python
# Input
x = torch.randn(8, 1, 3000)  # 8 epoch, 1 kanal, 3000 sample

model = NeuroGraphT(
    in_channels=1,
    conv_channels=[32, 64, 128],
    transformer_dim=128,
    num_heads=8,
    transformer_layers=4,
    d_ff=512,
    num_nodes=16,
    sparsity=25.0,
    thresholding="value",
    gcn_hidden=128,
    gcn_layers=3,
    num_classes=5,
    dropout=0.1
)

# Forward pass
logits = model(x)  # (8, 5)

# Prediction
predictions = logits.argmax(dim=1)  # (8,) - Her epoch iÃ§in tahmin
```

**Shape Transformations:**
```
(8, 1, 3000) â†’ CNN â†’ (8, 128, 64)
(8, 128, 64) â†’ Transformer â†’ (8, 64, 128)
(8, 64, 128) â†’ GraphBuilder â†’ nodes: (8, 16, 512), adj: (8, 16, 16)
(8, 16, 512) + (8, 16, 16) â†’ GCN â†’ (8, 128)
(8, 128) â†’ Classifier â†’ (8, 5)
```

---

## ğŸ”¬ Baseline Modeller

NeuroGraphT'in performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in iki baseline model kullanÄ±lÄ±r. Her ikisi de **graf modÃ¼lÃ¼ iÃ§ermez**, sadece CNN + Transformer kombinasyonudur.

### 1. BaselineCNNTransformer

**Mimari Ã–zellikler:**
- **CNN DerinliÄŸi**: 3 katman
- **Kernel Size**: Sabit (5, 5, 5)
- **Sequence Length**: 64 timestep
- **Pooling Strategy**: Global Average Pooling
- **Graf ModÃ¼lÃ¼**: âŒ YOK

```python
class BaselineCNNTransformer(nn.Module):
    def __init__(
        self,
        conv_channels=[32, 64, 128],     # 3 CNN katmanÄ±
        kernel_sizes=[5, 5, 5],          # Sabit kernel size
        transformer_dim=128,
        num_heads=8,
        num_layers=4,
        num_classes=5
    )
```

**Pipeline AkÄ±ÅŸÄ±:**
```
Input (batch, 1, 3000)
  â†“ CNN [32â†’64â†’128] kernel_size=5
  â†“ MaxPool (her katmanda /2)
  â†“ AdaptiveAvgPool1d(64)
  â†“ Shape: (batch, 128, 64)
  â†“
  â†“ Transpose â†’ (batch, 64, 128)
  â†“ Input Projection
  â†“ Positional Encoding
  â†“ Transformer (4 layers, 8 heads)
  â†“ Shape: (batch, 64, 128)
  â†“
  â†“ Global Average Pooling (mean over timesteps)
  â†“ Shape: (batch, 128)
  â†“
  â†“ Classifier (Linear)
Output (batch, 5)
```

**Karakteristik:**
- âœ… **HÄ±zlÄ± eÄŸitim**: Daha az CNN katmanÄ±
- âœ… **Average pooling**: Smooth, dengeli Ã¶zellik aggregation
- âœ… **64 timestep**: Daha fazla temporal resolution
- âŒ **SÄ±ÄŸ CNN**: Daha az feature extraction depth

---

### 2. Baseline1DCNNTransformer

**Mimari Ã–zellikler:**
- **CNN DerinliÄŸi**: 4 katman (daha derin!)
- **Kernel Size**: DeÄŸiÅŸken (7, 5, 5, 3) - Piramit stratejisi
- **Sequence Length**: 32 timestep (daha kompakt)
- **Pooling Strategy**: Global Max Pooling
- **Graf ModÃ¼lÃ¼**: âŒ YOK

```python
class Baseline1DCNNTransformer(nn.Module):
    def __init__(
        self,
        conv_channels=[32, 64, 128, 64],  # 4 CNN katmanÄ±
        kernel_sizes=[7, 5, 5, 3],        # DeÄŸiÅŸken kernel size
        transformer_dim=128,
        num_heads=8,
        num_layers=4,
        num_classes=5
    )
```

**Pipeline AkÄ±ÅŸÄ±:**
```
Input (batch, 1, 3000)
  â†“ CNN Layer 1: kernel=7 [1â†’32]   â† GeniÅŸ temporal pattern
  â†“ MaxPool â†’ 1500
  â†“ CNN Layer 2: kernel=5 [32â†’64]
  â†“ MaxPool â†’ 750
  â†“ CNN Layer 3: kernel=5 [64â†’128]
  â†“ MaxPool â†’ 375
  â†“ CNN Layer 4: kernel=3 [128â†’64] â† Lokal refinement
  â†“ MaxPool â†’ 187
  â†“ AdaptiveAvgPool1d(32)           â† Daha kÄ±sa sequence
  â†“ Shape: (batch, 64, 32)
  â†“
  â†“ Transpose â†’ (batch, 32, 64)
  â†“ Input Projection
  â†“ Positional Encoding
  â†“ Transformer (4 layers, 8 heads)
  â†“ Shape: (batch, 32, 128)
  â†“
  â†“ Global Max Pooling (max over timesteps)  â† FarklÄ±!
  â†“ Shape: (batch, 128)
  â†“
  â†“ Classifier (Linear)
Output (batch, 5)
```

**Karakteristik:**
- âœ… **Derin CNN**: 4 katman, daha zengin feature extraction
- âœ… **Piramit kernel**: 7â†’5â†’5â†’3 (geniÅŸâ†’dar)
- âœ… **Max pooling**: Belirgin Ã¶zellikleri vurgular
- âœ… **32 timestep**: Daha agresif sÄ±kÄ±ÅŸtÄ±rma, hesaplama tasarrufu
- âŒ **Daha fazla parametre**: Overfitting riski

---

### ğŸ†š BaselineCNNTransformer vs Baseline1DCNNTransformer

#### Temel Farklar Tablosu

| Ã–zellik | BaselineCNNTransformer | Baseline1DCNNTransformer |
|---------|----------------------|--------------------------|
| **CNN Katman SayÄ±sÄ±** | 3 | 4 (daha derin) |
| **Kernel Size** | [5, 5, 5] (sabit) | [7, 5, 5, 3] (deÄŸiÅŸken) |
| **Ä°lk Kernel** | 5 | **7** â† GeniÅŸ receptive field |
| **Son Kernel** | 5 | **3** â† Lokal refinement |
| **Adaptive Pool** | 64 timestep | 32 timestep (daha kompakt) |
| **Global Pooling** | **Average** | **Max** |
| **Parametre SayÄ±sÄ±** | Daha az | Daha fazla |
| **EÄŸitim HÄ±zÄ±** | HÄ±zlÄ± | Biraz daha yavaÅŸ |
| **Feature Extraction** | SÄ±ÄŸ, genel | Derin, detaylÄ± |

#### Kernel Size Stratejisi KarÅŸÄ±laÅŸtÄ±rmasÄ±

**BaselineCNNTransformer:**
```
Kernel=5 â†’ Kernel=5 â†’ Kernel=5
  â†“          â†“          â†“
Dengeli    Dengeli    Dengeli
```
- TÃ¼m katmanlarda aynÄ± receptive field
- Uniform feature extraction

**Baseline1DCNNTransformer:**
```
Kernel=7 â†’ Kernel=5 â†’ Kernel=5 â†’ Kernel=3
  â†“          â†“          â†“          â†“
GeniÅŸ      Orta       Orta       Dar
Pattern    Features   Features   Details
```
- **Ä°lk katman (7)**: GeniÅŸ temporal pattern'ler yakalar (delta dalgalarÄ±)
- **Orta katmanlar (5,5)**: Dengeli feature extraction
- **Son katman (3)**: Lokal detaylarÄ± refine eder (spindle'lar)

#### Pooling Strategy FarkÄ±

**Global Average Pooling (BaselineCNNTransformer):**
```python
x = x.mean(dim=1)  # TÃ¼m timestep'lerin ortalamasÄ±
```
- **Smooth aggregation**: TÃ¼m temporal bilgiyi dengeli kullanÄ±r
- **Robust**: Outlier'lara duyarlÄ± deÄŸil
- **Genel pattern'ler**: Overall aktivite seviyesi
- **Ã–rnek**: N2 evresi â†’ K-kompleks + spindle'larÄ±n genel karakteri

**Global Max Pooling (Baseline1DCNNTransformer):**
```python
x = x.max(dim=1)[0]  # Her feature'Ä±n maksimum aktivasyonu
```
- **Discriminative features**: En belirgin Ã¶zellikleri vurgular
- **Sparse activation**: Kritik anlarÄ± yakalar
- **Belirgin event'ler**: Spindle zirveleri, K-kompleks amplitudes
- **Ã–rnek**: N2 evresi â†’ En yÃ¼ksek spindle amplitÃ¼dÃ¼

#### Sequence Length Etkisi

**64 Timestep (BaselineCNNTransformer):**
- Daha fazla temporal resolution
- Transformer iÃ§in daha uzun attention
- Daha ince temporal dynamics yakalama
- Hesaplama: O(64Â²) = 4096 attention operations

**32 Timestep (Baseline1DCNNTransformer):**
- Daha kompakt representation
- Daha hÄ±zlÄ± transformer processing
- Agresif feature sÄ±kÄ±ÅŸtÄ±rma
- Hesaplama: O(32Â²) = 1024 attention operations (4x hÄ±zlÄ±!)

#### Hangi Model Ne Zaman Ä°yi?

**BaselineCNNTransformer kullanÄ±lmalÄ±:**
- âœ… Smooth, genel pattern'ler Ã¶nemli olduÄŸunda
- âœ… Overfitting riski yÃ¼ksek olduÄŸunda (az veri)
- âœ… HÄ±zlÄ± eÄŸitim gerektiÄŸinde
- âœ… TÃ¼m temporal bilgi eÅŸit Ã¶nemde olduÄŸunda

**Baseline1DCNNTransformer kullanÄ±lmalÄ±:**
- âœ… Belirgin, diskriminatif Ã¶zellikler arandÄ±ÄŸÄ±nda
- âœ… Yeterli veri olduÄŸunda (overfitting iÃ§in)
- âœ… Daha detaylÄ± feature extraction gerektiÄŸinde
- âœ… Kritik event'ler (spindle'lar, K-kompleks) Ã¶nemli olduÄŸunda

#### Pratik Performans Beklentileri

**Sleep Stage SÄ±nÄ±flandÄ±rmada:**

| SÄ±nÄ±f | BaselineCNNTransformer | Baseline1DCNNTransformer |
|-------|----------------------|--------------------------|
| **W (Wake)** | 90% F1 | 91% F1 (max pool iyi) |
| **N1** | 45% F1 | 50% F1 (derin CNN yardÄ±mcÄ±) |
| **N2** | 85% F1 | 87% F1 (spindle detection) |
| **N3** | 88% F1 | 89% F1 (delta waves) |
| **REM** | 83% F1 | 84% F1 |
| **Overall** | ~80% | ~82% |

**GÃ¶zlem:**
- 1D-CNN-Transformer genellikle +1-2% daha iyi performans
- Ancak daha uzun eÄŸitim sÃ¼resi gerektirir
- KÃ¼Ã§Ã¼k veri setlerinde overfitting riski

---

### Kod KarÅŸÄ±laÅŸtÄ±rmasÄ±

**BaselineCNNTransformer - Forward Pass:**
```python
def forward(self, x):
    # CNN feature extraction
    x = self.cnn(x)                      # (B, 128, L)
    x = self.adaptive_pool(x)            # (B, 128, 64)
    
    # Transformer encoding
    x = x.permute(0, 2, 1)               # (B, 64, 128)
    x = self.input_projection(x)         # (B, 64, 128)
    x = self.positional_encoding(x)
    x = self.transformer(x)              # (B, 64, 128)
    
    # Global average pooling
    x = x.mean(dim=1)                    # (B, 128) â† Average!
    
    # Classification
    x = self.dropout(x)
    return self.fc(x)                    # (B, 5)
```

**Baseline1DCNNTransformer - Forward Pass:**
```python
def forward(self, x):
    # Daha derin CNN feature extraction
    x = self.cnn(x)                      # (B, 64, L) â† 4 layers!
    x = self.adaptive_pool(x)            # (B, 64, 32) â† Shorter!
    
    # Transformer encoding
    x = x.permute(0, 2, 1)               # (B, 32, 64)
    x = self.input_projection(x)         # (B, 32, 128)
    x = self.positional_encoding(x)
    x = self.transformer(x)              # (B, 32, 128)
    
    # Global max pooling
    x = x.max(dim=1)[0]                  # (B, 128) â† Max!
    
    # Classification
    x = self.dropout(x)
    return self.fc(x)                    # (B, 5)
```

---

## ï¿½ LiteratÃ¼r KarÅŸÄ±laÅŸtÄ±rmasÄ± ve Benchmark SonuÃ§larÄ±

### Sleep-EDF Veri Seti Ãœzerinde State-of-the-Art SonuÃ§lar

Bu bÃ¶lÃ¼m, **Sleep-EDF Database** Ã¼zerinde yapÄ±lmÄ±ÅŸ baÅŸlÄ±ca akademik Ã§alÄ±ÅŸmalarÄ±n performans metriklerini iÃ§ermektedir. TÃ¼m sonuÃ§lar **5-sÄ±nÄ±f sÄ±nÄ±flandÄ±rma** (W, N1, N2, N3, REM) iÃ§in rapor edilmiÅŸtir.

---

### ğŸ† Temel Benchmark Modeller

#### 1. **DeepSleepNet** (Supratak et al., 2017)
**YayÄ±n:** IEEE Transactions on Neural Systems and Rehabilitation Engineering  
**Mimari:** CNN-BiLSTM (Ä°ki aÅŸamalÄ± Ã¶ÄŸrenme)

**Sleep-EDF-20 (Fpz-Cz) SonuÃ§larÄ±:**
```
Overall Accuracy: 82.0%
Macro F1-Score:   76.9%
Cohen's Kappa:    0.76

Per-class F1-scores:
  W:   89.2%
  N1:  50.3%  â† En zor sÄ±nÄ±f
  N2:  85.1%
  N3:  84.7%
  REM: 81.4%
```

**Mimari DetaylarÄ±:**
- **Representation Learning**: CNN (small + large filters) + Dropout-based Regularization
- **Sequence Residual Learning**: BiLSTM (2 layers)
- **Ä°ki aÅŸamalÄ± eÄŸitim**: Ã–nce CNN, sonra BiLSTM fine-tuning
- **Input**: 30s epoch, tek kanal EEG (Fpz-Cz)
- **Parametre sayÄ±sÄ±**: ~3.5M

**Avantajlar:** âœ… Robust temporal modeling, âœ… Ä°ki filtre boyutu (3s + 0.5s)  
**Dezavantajlar:** âŒ Ä°ki aÅŸamalÄ± eÄŸitim karmaÅŸÄ±k, âŒ BiLSTM yavaÅŸ

---

#### 2. **U-Time** (Perslev et al., 2019)
**YayÄ±n:** NeurIPS 2019  
**Mimari:** Fully Convolutional U-Net (Temporal segmentation)

**Sleep-EDF-153 SonuÃ§larÄ±:**
```
Overall Accuracy: 81.7% (mean)
Cohen's Kappa:    0.75 Â± 0.08
Macro F1-Score:   ~75%

Hiperparametre robustluÄŸu: Ã‡ok yÃ¼ksek
Cross-dataset transfer: MÃ¼kemmel
```

**Mimari DetaylarÄ±:**
- **U-Net Encoder-Decoder**: 12-layer fully convolutional
- **Segment-to-segment mapping**: Her zaman adÄ±mÄ± iÃ§in sÄ±nÄ±f tahmini
- **Multi-resolution feature extraction**: Skip connections
- **No recurrence**: Tamamen feed-forward
- **Input**: Uzun sequence (>30s), flexible length

**Avantajlar:** âœ… Hiperparametre robustluÄŸu, âœ… Transfer learning iÃ§in mÃ¼kemmel, âœ… HÄ±zlÄ±  
**Dezavantajlar:** âŒ Temporal context sÄ±nÄ±rlÄ±, âŒ LSTM kadar sequential modeling yok

---

#### 3. **L-SeqSleepNet** (Phan et al., 2023)
**YayÄ±n:** IEEE Journal of Biomedical and Health Informatics  
**Mimari:** Long-sequence modeling with Hierarchical RNN

**Sleep-EDF-20 (Fpz-Cz) SonuÃ§larÄ±:**
```
Overall Accuracy: 83.4%
Macro F1-Score:   78.2%
Cohen's Kappa:    0.78

Per-class F1-scores:
  W:   90.1%
  N1:  53.8%  â† Ä°yileÅŸme!
  N2:  86.5%
  N3:  85.2%
  REM: 82.5%
```

**Mimari DetaylarÄ±:**
- **Whole-cycle modeling**: ~90 dakikalÄ±k sequence (180 epoch)
- **Hierarchical architecture**: Epoch-level â†’ Cycle-level
- **Adaptive Feature Recalibration**: Attention-like mechanism
- **Training strategy**: Curriculum learning

**Avantajlar:** âœ… Uzun-menzilli temporal baÄŸÄ±mlÄ±lÄ±klar, âœ… N1 sÄ±nÄ±fÄ±nda iyileÅŸme  
**Dezavantajlar:** âŒ Ã‡ok uzun sequence gerektirir, âŒ HafÄ±za yoÄŸun

---

#### 4. **NeuroNet** (Lee et al., 2024)
**YayÄ±n:** arXiv 2404.17585 (Under review)  
**Mimari:** Self-supervised pre-training + CNN-Transformer

**Sleep-EDF-20 SonuÃ§larÄ±:**
```
Overall Accuracy: 84.7%  â† SOTA!
Macro F1-Score:   80.5%
Cohen's Kappa:    0.80

Self-supervised pre-training benefits:
  - Baseline (from scratch): 82.0% Acc
  - With pre-training:       84.7% Acc (+2.7%)
```

**Mimari DetaylarÄ±:**
- **Pre-training**: Contrastive learning + Temporal masking
- **Architecture**: 1D CNN + Multi-head self-attention
- **Data augmentation**: Time warping, jittering, masking
- **Fine-tuning**: Task-specific classifier

**Avantajlar:** âœ… Self-supervised learning, âœ… Az veriyle yÃ¼ksek performans  
**Dezavantajlar:** âŒ Pre-training maliyeti yÃ¼ksek

---

#### 5. **SleepTransformer** (Phan et al., 2022)
**YayÄ±n:** arXiv 2211.13005  
**Mimari:** Pure Transformer (CNN-free)

**Sleep-EDF SonuÃ§larÄ±:**
```
Overall Accuracy: 83.1%
Macro F1-Score:   77.8%
Cohen's Kappa:    0.77

Inference speed: 3x faster than BiLSTM
```

**Mimari DetaylarÄ±:**
- **Multi-scale Transformer**: FarklÄ± temporal resolution'larda attention
- **Positional encoding**: Learnable + Sinusoidal
- **No CNN**: DoÄŸrudan EEG raw signal Ã¼zerinde
- **Efficiency**: Linear attention (Linformer-style)

**Avantajlar:** âœ… HÄ±zlÄ± inference, âœ… Paralel eÄŸitim  
**Dezavantajlar:** âŒ CNN'siz lokal pattern yakalama zor

---

### ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rma Tablosu

| Model | Year | Architecture | Accuracy | F1-Macro | Kappa | N1 F1 | Params |
|-------|------|-------------|----------|----------|-------|-------|--------|
| **DeepSleepNet** | 2017 | CNN-BiLSTM | 82.0% | 76.9% | 0.76 | 50.3% | 3.5M |
| **U-Time** | 2019 | U-Net FCN | 81.7% | ~75% | 0.75 | ~48% | 2.8M |
| **SleepTransformer** | 2022 | Pure Transformer | 83.1% | 77.8% | 0.77 | 52.1% | 4.2M |
| **L-SeqSleepNet** | 2023 | Hierarchical RNN | 83.4% | 78.2% | 0.78 | 53.8% | 5.1M |
| **NeuroNet (SSL)** | 2024 | CNN-Transformer + SSL | **84.7%** | **80.5%** | **0.80** | **55.2%** | 3.8M |
| **NeuroGraphT (Ours)** | 2026 | CNN-Transformer-GNN | **ğŸ¯ Target** | **ğŸ¯ Target** | **ğŸ¯ Target** | **ğŸ¯ Target** | ~4.5M |

**Notlar:**
- TÃ¼m sonuÃ§lar Sleep-EDF-20 (Fpz-Cz) Ã¼zerinde 5-class classification
- N1 F1: En zor sÄ±nÄ±f, literatÃ¼rde genellikle 45-55% aralÄ±ÄŸÄ±nda
- Kappa: Cohen's Kappa coefficient (inter-rater agreement metric)

---

### ğŸ”¬ Graf TabanlÄ± YaklaÅŸÄ±mlar (Yeni Trend!)

#### **GraphSleepNet** (Jia et al., 2020)
**YayÄ±n:** EMBC 2020  
**Mimari:** GCN + LSTM

**Multi-channel EEG (6 kanal) SonuÃ§larÄ±:**
```
Overall Accuracy: 85.2%
Macro F1-Score:   80.8%
```

**Not:** Multi-channel kullanÄ±yor (6 EEG + 2 EOG), tek kanalla karÅŸÄ±laÅŸtÄ±rma zor!

#### **Spatial-Temporal GNN** (Shi et al., 2021)
**Mimari:** Spatial GCN + Temporal GCN

**Avantaj:** Electrode-level graph + Temporal graph  
**Dezavantaj:** Pre-defined electrode graph (fixed topology)

---

### ğŸ¯ NeuroGraphT'nin YenilikÃ§i KatkÄ±larÄ±

| Ã–zellik | DeepSleepNet | U-Time | L-SeqSleepNet | NeuroNet | **NeuroGraphT (Ours)** |
|---------|--------------|--------|---------------|----------|----------------------|
| **Architecture** | CNN-BiLSTM | U-Net FCN | Hierarchical RNN | CNN-Transformer | **CNN-Transformer-GCN** |
| **Temporal Modeling** | BiLSTM | U-Net Conv | BiLSTM | Transformer | âœ… **Transformer** |
| **Graph Learning** | âŒ | âŒ | âŒ | âŒ | âœ… **Adaptive GCN** |
| **Self-Supervised** | âŒ | âŒ | âŒ | âœ… | âœ… **Contrastive + Masking** |
| **Dynamic Graph** | âŒ | âŒ | âŒ | âŒ | âœ… **Data-driven adjacency** |
| **Single-channel** | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Training Speed** | Slow | Fast | Very Slow | Medium | Medium |

**Bizim Yeniliklerimiz:**
1. âœ… **Adaptive Graph Construction**: Data-driven adjacency matrix (korelasyon tabanlÄ±)
2. âœ… **Hybrid Architecture**: CNN + Transformer + GCN (Ã¼Ã§ modÃ¼l birlikte)
3. âœ… **Sparsity Control**: Value/Connection thresholding ile seyrek graf
4. âœ… **Self-Supervised Pre-training**: EEG temsillerini gÃ¼Ã§lendirme
5. âœ… **Transformer for Temporal**: LSTM'den hÄ±zlÄ± ve robust

---

### ğŸ“ˆ Beklenen Hedef Performans

**Sleep-EDF-153 (TÃ¼m SC dataset) iÃ§in:**

```yaml
Target Metrics:
  Overall Accuracy:  84-86%  # NeuroNet'i geÃ§mek
  Macro F1-Score:    80-82%  # State-of-the-art seviye
  Cohen's Kappa:     0.78-0.82
  
Per-class F1 Targets:
  W:    90-92%   # Kolay sÄ±nÄ±f
  N1:   54-58%   # Kritik sÄ±nÄ±f - literatÃ¼rden iyi
  N2:   86-88%   # En yaygÄ±n sÄ±nÄ±f
  N3:   85-88%   # Delta detection
  REM:  83-85%   # REM detection
```

**Graf ModÃ¼lÃ¼nÃ¼n Beklenen KatkÄ±sÄ±:**
- Baseline (CNN-Transformer only): ~82-83% accuracy
- **+Graf ModÃ¼lÃ¼**: ~84-86% accuracy (**+2-3%** artÄ±ÅŸ bekleniyor)
- **+Self-supervised pre-training**: ~+1-2% ek boost

---

### ğŸ” LiteratÃ¼r Analizi: Kritik GÃ¶zlemler

**1. N1 SÄ±nÄ±fÄ± ZorluklarÄ±:**
- TÃ¼m modeller N1'de dÃ¼ÅŸÃ¼k performans (~45-55% F1)
- Neden: Az Ã¶rnek + belirsiz Ã¶zellikler + N2'ye geÃ§iÅŸ evresi
- Ã‡Ã¶zÃ¼m: Weighted loss + data augmentation + temporal context

**2. Temporal Modeling Trendi:**
- 2017-2020: LSTM/BiLSTM dominanttÄ±
- 2021-2024: Transformer'a geÃ§iÅŸ (**3-5x hÄ±zlÄ±**)
- 2024+: Self-attention + Graph learning kombinasyonu

**3. Self-Supervised Learning Impact:**
- NeuroNet (2024): +2.7% accuracy boost with SSL
- Trend: Pre-training stratejileri popÃ¼laritesi artÄ±yor
- KÃ¼Ã§Ã¼k veri setlerinde kritik Ã¶nemi var

**4. Graf TabanlÄ± YaklaÅŸÄ±mlarÄ±n Potansiyeli:**
- Multi-channel EEG'de baÅŸarÄ±lÄ± (85%+ accuracy)
- Tek kanal iÃ§in henÃ¼z yeterli Ã§alÄ±ÅŸma yok
- Adaptive graph construction: Yeni araÅŸtÄ±rma alanÄ±

---

### ğŸ“– Referans Makaleler

1. **Supratak et al. (2017)** - DeepSleepNet  
   IEEE Trans. Neural Syst. Rehabil. Eng. | Citations: 1200+

2. **Perslev et al. (2019)** - U-Time  
   NeurIPS 2019 | Citations: 400+

3. **Phan et al. (2023)** - L-SeqSleepNet  
   IEEE J. Biomed. Health Inform. | Citations: 80+

4. **Lee et al. (2024)** - NeuroNet (Self-supervised)  
   arXiv:2404.17585 | Under Review

5. **Jia et al. (2020)** - GraphSleepNet  
   EMBC 2020 | Citations: 120+

---

## ï¿½ğŸ“ˆ EÄŸitim ve DeÄŸerlendirme

### Loss Function

```python
# Weighted Cross-Entropy (dengesiz veri iÃ§in)
from sklearn.utils.class_weight import compute_class_weight

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(labels),
    y=labels
)
criterion = nn.CrossEntropyLoss(
    weight=torch.FloatTensor(class_weights)
)
```

**Neden Weighted?**
- N1 sÄ±nÄ±fÄ± Ã§ok az (~5%) â†’ AÄŸÄ±rlÄ±k artÄ±rÄ±lÄ±r
- N2 sÄ±nÄ±fÄ± Ã§ok fazla (~45%) â†’ AÄŸÄ±rlÄ±k azaltÄ±lÄ±r

### Optimizer

```python
optimizer = AdamW(
    model.parameters(),
    lr=0.0001,           # Transformer iÃ§in dÃ¼ÅŸÃ¼k LR
    weight_decay=0.01    # L2 regularization
)
```

**AdamW > Adam:**
- Decoupled weight decay
- Daha iyi generalization

### Learning Rate Scheduler

```python
# Warmup + Cosine Annealing
warmup = LinearLR(
    optimizer,
    start_factor=0.1,
    total_iters=5  # 5 epoch warmup
)

cosine = CosineAnnealingLR(
    optimizer,
    T_max=100,     # Max epoch
    eta_min=1e-6   # Minimum LR
)

scheduler = SequentialLR(
    optimizer,
    [warmup, cosine],
    milestones=[5]
)
```

### EÄŸitim DÃ¶ngÃ¼sÃ¼

```python
for epoch in range(num_epochs):
    # Training
    train_metrics = train_one_epoch(
        model, train_loader, criterion, optimizer, device
    )
    
    # Validation
    val_metrics = validate(
        model, val_loader, criterion, device
    )
    
    # LR scheduling
    scheduler.step()
    
    # Checkpoint saving
    if val_metrics['f1'] > best_f1:
        best_f1 = val_metrics['f1']
        torch.save(model.state_dict(), 'best_model.pt')
```

### DeÄŸerlendirme Metrikleri

```python
from utils.metrics import calculate_all_metrics

metrics = calculate_all_metrics(y_true, y_pred)
# {
#     'accuracy': 85.3,     # Genel doÄŸruluk
#     'precision': 82.1,    # Macro-average precision
#     'recall': 81.7,       # Macro-average recall
#     'f1': 81.9            # Macro-average F1 (en Ã¶nemli)
# }
```

**Neden Macro F1?**
- Her sÄ±nÄ±fÄ± eÅŸit Ã¶nemde deÄŸerlendirir
- Dengesiz veri setlerinde daha gÃ¼venilir
- N1 gibi az temsil edilen sÄ±nÄ±flarÄ± da dikkate alÄ±r

### Confusion Matrix

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', 
            xticklabels=['W', 'N1', 'N2', 'N3', 'REM'],
            yticklabels=['W', 'N1', 'N2', 'N3', 'REM'])
```

**Yorumlama:**
- Diagonal: DoÄŸru tahminler
- Off-diagonal: KarÄ±ÅŸÄ±klÄ±klar (Ã¶r. N1 vs N2)

---

## ğŸ”¬ KarÅŸÄ±laÅŸtÄ±rmalÄ± Deneyler

### Deney KonfigÃ¼rasyonlarÄ±

```python
EXPERIMENTS = [
    # Baseline modeller (graf yok)
    ("CNN-Transformer", None, None),
    ("1D-CNN-Transformer", None, None),
    
    # NeuroGraphT varyasyonlarÄ±
    ("NeuroGraphT", 50, "value"),
    ("NeuroGraphT", 25, "value"),
    ("NeuroGraphT", 50, "connection"),
    ("NeuroGraphT", 25, "connection"),
]
```

### Parametre Analizi

| Model | Sparsity | Threshold | Node Count | AÃ§Ä±klama |
|-------|----------|-----------|------------|----------|
| Baseline | - | - | - | Graf yok |
| NeuroGraphT-V50 | 50% | Value | 16 | YoÄŸun graf |
| NeuroGraphT-V25 | 25% | Value | 16 | Seyrek graf |
| NeuroGraphT-C50 | 50% | Connection | 16 | Her node'da 8 baÄŸlantÄ± |
| NeuroGraphT-C25 | 25% | Connection | 16 | Her node'da 4 baÄŸlantÄ± |

### Ã‡alÄ±ÅŸtÄ±rma

```bash
# TÃ¼m deneyleri Ã§alÄ±ÅŸtÄ±r
python run_all_experiments.py \
    --num-runs 3 \
    --max-subjects 10 \
    --config config/config.yaml

# K-fold cross validation
python run_experiments_kfold.py \
    --k-folds 5 \
    --config config/config.yaml
```

### SonuÃ§ Analizi

```python
import json

with open("results.json") as f:
    results = json.load(f)

for model_name, metrics in results["experiments"].items():
    print(f"{model_name}:")
    print(f"  Accuracy: {metrics['accuracy']:.2f}% Â± {metrics['accuracy_std']:.2f}%")
    print(f"  F1 Score: {metrics['f1']:.2f}% Â± {metrics['f1_std']:.2f}%")
```

### Beklenen SonuÃ§lar (LiteratÃ¼r)

| Model Type | Accuracy | F1-Score | Notlar |
|------------|----------|----------|--------|
| CNN-LSTM | ~78-82% | ~75-79% | Baseline |
| CNN-Transformer | ~80-84% | ~77-81% | LSTM'den iyi |
| **NeuroGraphT** | ~82-86% | ~79-83% | Graf ile artÄ±ÅŸ |

**Graf ModÃ¼lÃ¼nÃ¼n KatkÄ±sÄ±:**
- âœ… +2-4% accuracy
- âœ… +2-3% F1-score
- âœ… Ã–zellikle N1 ve N3 sÄ±nÄ±flarÄ±nda iyileÅŸme

---

## ğŸš€ KullanÄ±m Ã–rnekleri

### HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Jupyter Notebook)

```python
# 1. Veri setini indir
from data.download import ensure_dataset
data_path = ensure_dataset(verbose=True)

# 2. Model oluÅŸtur
from models import NeuroGraphT
model = NeuroGraphT(num_classes=5)

# 3. Basit test
import torch
test_input = torch.randn(2, 1, 3000)
output = model(test_input)
print(output.shape)  # (2, 5)
```

### Python Script ile EÄŸitim

```python
from data import create_data_loaders
from models import NeuroGraphT
import torch
import torch.nn as nn

# DataLoader
loaders = create_data_loaders(
    batch_size=32,
    max_subjects=20,
    verbose=True
)

# Model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = NeuroGraphT(
    num_classes=5,
    sparsity=25.0,
    thresholding="value"
).to(device)

# Training
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)

for epoch in range(100):
    # Training loop...
    pass
```

---

## ğŸ“Š Hiperparametre Tablosu

### CNN Parametreleri
```yaml
in_channels: 1
conv_channels: [32, 64, 128]
kernel_sizes: [5, 5, 5]
pool_size: 2
```

### Transformer Parametreleri
```yaml
d_model: 128
num_heads: 8
num_layers: 4
d_ff: 512
dropout: 0.1
```

### Graf Parametreleri
```yaml
num_nodes: 16
sparsity: 25  # veya 50
thresholding: "value"  # veya "connection"
```

### GCN Parametreleri
```yaml
hidden_channels: 128
num_layers: 3
dropout: 0.1
```

### EÄŸitim Parametreleri
```yaml
batch_size: 32
num_epochs: 100
learning_rate: 0.0001
weight_decay: 0.01
warmup_epochs: 5
```

---

## ğŸ“ Temel Kavramlar

### EEG (Electroencephalogram)
Beyin elektriksel aktivitesinin kayÄ±t edilmesi. Uyku evrelerinde farklÄ± frekans bantlarÄ± dominanttÄ±r:
- **Delta (<4 Hz)**: Derin uyku (N3, slow-wave sleep)
- **Theta (4-7 Hz)**: Hafif uyku (N1, drowsiness)
- **Alpha (8-12 Hz)**: UyanÄ±klÄ±k (gÃ¶zler kapalÄ±, relaxed wakefulness)
- **Beta (13-30 Hz)**: Aktif uyanÄ±klÄ±k (alert, active thinking)
- **Gamma (>30 Hz, typically ~30-100 Hz)**: YÃ¼ksek konsantrasyon, cross-modal sensory processing

### Transformer
Self-attention mekanizmasÄ± kullanan model. Her pozisyon, tÃ¼m diÄŸer pozisyonlara attention yapabilir.

### Graph Neural Network
Graf yapÄ±lÄ± veriler Ã¼zerinde Ã§alÄ±ÅŸan sinir aÄŸlarÄ±. Node'lar arasÄ± iliÅŸkileri Ã¶ÄŸrenir.

### Sparsity (Seyreklik)
Graf yapÄ±sÄ±ndaki baÄŸlantÄ± oranÄ±. DÃ¼ÅŸÃ¼k sparsity = daha az baÄŸlantÄ± = daha seyrek graf.

---

## ğŸ“š Referanslar

### Veri Seti
- **Sleep-EDF Database**: https://physionet.org/content/sleep-edfx/1.0.0/
- Kemp, B., et al. (2000). "Analysis of a sleep-dependent neuronal feedback loop"

### Metodoloji
- **Transformer**: Vaswani et al. (2017) "Attention Is All You Need"
- **GCN**: Kipf & Welling (2017) "Semi-Supervised Classification with Graph Convolutional Networks"
- **Sleep Stage Classification**: Phan et al. (2019) "DeepSleepNet"

---

## ğŸ› ï¸ GeliÅŸtirme NotlarÄ±

### Performans OptimizasyonlarÄ±
1. **Mixed Precision Training**: `torch.cuda.amp` ile 2x hÄ±zlanma
2. **DataLoader Workers**: `num_workers=4` ile veri yÃ¼kleme paralelleÅŸtirme
3. **Gradient Accumulation**: Daha bÃ¼yÃ¼k batch size simulasyonu

### Gelecek Ä°yileÅŸtirmeler
- [ ] Multi-channel EEG desteÄŸi (Fpz-Cz + Pz-Oz)
- [ ] Attention visualization
- [ ] Graph structure analysis
- [ ] Real-time inference optimization
- [ ] Transfer learning (farklÄ± veri setleri)

---

## ğŸ“ Ä°letiÅŸim ve Destek

**Proje Sahibi:** [GitHub Repository]

**Lisans:** MIT

**Son GÃ¼ncelleme:** 6 Ocak 2025

---

**Not:** Bu dokÃ¼mantasyon, projenin teknik detaylarÄ±nÄ± ve kullanÄ±mÄ±nÄ± kapsamlÄ± ÅŸekilde aÃ§Ä±klamaktadÄ±r. SorularÄ±nÄ±z iÃ§in issue aÃ§abilir veya katkÄ±da bulunabilirsiniz.
